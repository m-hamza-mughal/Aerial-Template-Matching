{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Algorithm with SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdal\n",
    "ds = gdal.Open('1.tif')\n",
    "width = ds.RasterXSize\n",
    "height = ds.RasterYSize\n",
    "gt = ds.GetGeoTransform()\n",
    "\n",
    "from osgeo import osr\n",
    "srs = osr.SpatialReference()\n",
    "srs.ImportFromWkt(ds.GetProjection())\n",
    "\n",
    "srsLatLong = srs.CloneGeogCS()\n",
    "ct = osr.CoordinateTransformation(srs,srsLatLong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from scipy import misc\n",
    "\n",
    "def template_tracker(link_in='data.mp4', link_out='output_sift.mp4'):\n",
    "    print(\"opening video file...\")\n",
    "    vs = cv2.VideoCapture(link_in)\n",
    "\n",
    "    writer = None\n",
    "    W = None\n",
    "    H = None\n",
    "\n",
    "    totalFrames = 0\n",
    "    check=False\n",
    "    while True:\n",
    "        frame = vs.read()\n",
    "        frame = frame[1]\n",
    "        \n",
    "        if link_in is not None and frame is None:\n",
    "            print(\"end\")\n",
    "            check=True\n",
    "            break\n",
    "\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        rgb = misc.imresize(rgb, 0.75)\n",
    "\n",
    "        if W is None or H is None:\n",
    "            (H, W) = frame.shape[:2]\n",
    "\n",
    "        if writer is None:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "            writer = cv2.VideoWriter(link_out, fourcc, 30, (2448,1779), True)\n",
    "        # Initiate SIFT detector\n",
    "        sift = cv2.xfeatures2d.SIFT_create()\n",
    "        MIN_MATCH_COUNT = 10\n",
    "        \n",
    "        if totalFrames % 16 == 0:\n",
    "            \n",
    "            img1 = rgb        # queryImage\n",
    "            img2 = plt.imread('1.tif') # trainImage            \n",
    "            \n",
    "            # find the keypoints and descriptors with SIFT\n",
    "            kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "            kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "\n",
    "            FLANN_INDEX_KDTREE = 0\n",
    "            index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 2)\n",
    "            search_params = dict(checks = 2)\n",
    "\n",
    "            flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "            matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "            # store all the good matches as per Lowe's ratio test.\n",
    "            good = []\n",
    "            for m,n in matches:\n",
    "                if m.distance < 0.7*n.distance:\n",
    "                    good.append(m)\n",
    "                    \n",
    "            if len(good)>MIN_MATCH_COUNT:\n",
    "                src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "                dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "\n",
    "                M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "                matchesMask = mask.ravel().tolist()\n",
    "\n",
    "                h,w = img1.shape[:2]\n",
    "                pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "                dst = cv2.perspectiveTransform(pts,M)\n",
    "                points= np.int32(dst)\n",
    "                #print(points)\n",
    "                img2 = cv2.polylines(img2,[np.int32(dst)],True,255,5, cv2.LINE_8)\n",
    "                \n",
    "                M = cv2.moments(points)\n",
    "                \n",
    "                cx = int(M['m10']/M['m00'])\n",
    "                cy = int(M['m01']/M['m00'])\n",
    "                \n",
    "                img2= cv2.circle(img2, (cx, cy), 4, (0, 255, 255), 10)\n",
    "                ax= gt[0] + cx*gt[1] + cy*gt[2]\n",
    "                ay= gt[3] + cx*gt[4] + cy*gt[5]\n",
    "                coord= ct.TransformPoint(ax,ay)\n",
    "                lat= coord[0]\n",
    "                long= coord[1]\n",
    "                #print(long,lat)\n",
    "                \n",
    "            else:\n",
    "                print(\"Not enough matches are found - %d/%d\" % (len(good),MIN_MATCH_COUNT))\n",
    "                matchesMask = None\n",
    "        \n",
    "        draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "                   singlePointColor = None,\n",
    "                   matchesMask = matchesMask, # draw only inliers\n",
    "                   flags = 2)\n",
    "\n",
    "        img3 = cv2.drawMatches(img1,kp1,img2[:,:,:3],kp2,good,None,**draw_params)\n",
    "        img3= cv2.putText(img3, str(lat)+' East', (10,1720), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "        img3= cv2.putText(img3, str(long)+' North', (10,1650), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "        \n",
    "        \n",
    "        nigg=cv2.cvtColor(img3, cv2.COLOR_RGB2BGR)\n",
    "        #print(nigg.shape)\n",
    "        if writer is not None:\n",
    "            writer.write(nigg)\n",
    "        cv2.namedWindow(\"Frame\", cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(\"Frame\", nigg)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "            \n",
    "        if check:\n",
    "            break\n",
    "            \n",
    "\n",
    "        totalFrames += 1\n",
    "    print('done')\n",
    "    writer.release()\n",
    "    vs.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "template_tracker(link_in='our_data.mp4', link_out='output.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
